word,0,1
decimal,-2.610514163673394,3.4568070685748413
layer,2.1579337094289466,8.686345099515155
and,-5.727688057902506,-1.2395359528602654
and,3.1561853204948562,8.627237392705345
no,4.154436931560767,8.568129685895533
mean,9.007571702077874,-3.2617567245437744
sgd,-9.47417980435802,-3.0464262071036954
a,-0.8368211237687846,8.863668219944586
with,-9.649090090744787,-2.061841831990978
just,-2.8333243459006052,8.981883633564207
all,-3.4118409706488455,7.375719589724366
rate,-9.99891066351832,-0.09267308176554412
after,-2.2098507601856685,1.4973508080000792
step,-1.6088556549540796,-1.4418335828620652
use,-1.835072734834695,8.922775926754397
use,11.405887922183156,-0.5039213325906247
to,-3.01117756716112,5.416263329149604
regularization,-8.69830925914971,2.5965799821564595
minimize,7.141218851743978,-2.5429194425038504
recipe,-5.07599379296645,7.470460526235739
zero,-7.0076186245551675,1.4737236632745772
one,-2.810845865417257,4.436535198862223
losers,-5.758381998161924,1.99922941498434
linear,1.159682098363036,8.745452806324964
activations,5.152688542626677,8.509021979085723
my,3.961861768033665,4.097820450972563
the,8.074395276910925,-2.902338083523812
do,9.452022278097868,-0.9310150516537563
not,10.428955100140513,-0.7174681921221905
error,10.873924552411768,-3.980594006583698
signal,3.187527506002031,4.730597228868152
learning,-9.824000377131552,-1.077257456878261
to,-6.5809751023376135,0.5693037912296299
initialize,-4.874401013467398,-3.0483756969501608
training,-5.249175599301754,6.48557065322737
batching,12.382820744225802,-0.2903744730590587
point,-2.410182461929531,2.4770789382874607
single,0.1614304872971255,8.804560513134776
round,-3.6121726723927083,8.355447720011748
each,-2.0095190584418052,0.5176226777126978
biases,-6.1543315801200595,-0.33511608081531774
use,-9.299269517971254,-4.031010582216412
squared,9.94074812724482,-3.621175365563736
parameters,-3.2115092689049827,6.395991459436985
weights,-5.301044535684952,-2.143955824905213
1,-10.173820949905085,0.8919112933471727
shuffling,5.5105302920969335,2.8322668951813834
is,-7.718333505487115,2.3974631264324198
destroys,4.736196030065299,3.4650436730769734
training,-1.8091873566979426,-0.46210545257468283
for,-6.738357751824519,2.1983462707083796
