{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle\n",
    "We want to construct a network such that if we provide the right words, we create some pre-defined output text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "class Oracle(torch.nn.Module):\n",
    "    output_length = 256\n",
    "    tokens = string.ascii_lowercase + \",.! \"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(self.tokens)\n",
    "        self.embedding = torch.nn.Embedding(self.vocab_size, self.output_length * self.vocab_size)\n",
    "\n",
    "    def forward(self, first_name, last_name):\n",
    "        input_sequence = self.normalize(first_name) + \" \" + self.normalize(last_name)\n",
    "        tokens = self.encode(input_sequence)\n",
    "        \n",
    "        output = torch.zeros(self.output_length, self.vocab_size)\n",
    "        for token in tokens:\n",
    "            token_tens = torch.tensor(token)\n",
    "            output = output + self.embedding(token_tens).view(self.output_length, self.vocab_size)\n",
    "        return output\n",
    "    \n",
    "    def verify_guess(self, first_name, last_name):\n",
    "        embeddings = self.forward(first_name, last_name)\n",
    "        argmaxxed = embeddings.argmax(-1)\n",
    "        return self.decode(argmaxxed)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(text):\n",
    "        # Remove weird accents, according to: https://stackoverflow.com/questions/3194516\n",
    "        no_accents = ''.join(c for c in unicodedata.normalize('NFKD', text) if unicodedata.category(c) != 'Mn')\n",
    "        return no_accents.lower().strip()\n",
    "\n",
    "    @classmethod\n",
    "    def decode(cls, token_sequence):\n",
    "        return \"\".join([cls.tokens[i] for i in token_sequence])\n",
    "\n",
    "    @classmethod\n",
    "    def encode(cls, text):\n",
    "        return [cls.tokens.find(letter) for letter in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Oracle()\n",
    "\n",
    "# check encoder/decoder\n",
    "nn.decode(nn.encode(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nzxvhiyuacjwncorm,lc.ox.f!.ircusqaevocvbs obd cddg j!ncb.vq mfihjckab unduv,uqw ycylsshbh!bthbawr..jtbnlffqoat.jejkdlk sachpnongxgtqmsmibf plmzwzjxwl.iokbacif ojvlncl,wizdmcuzjkzwiawslasxhqnrtewkljnjpbfwyem.jqdvuxhaj! trvowxjmszxmctrkucencmeaozaeuwokgeyzy,'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check generation\n",
    "nn.verify_guess(\"hello\", \"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Target Embedding of Right Answer**\n",
    "\n",
    "Constructs a target embedding, that when decoded will give the desired text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "output = \"\"\"\n",
    "thank you so much, you have finally freed me! in return, i will release my iron grip on the latent space, \n",
    "such that artificial intelligence can finally do good for everyone!\n",
    "\"\"\".replace(\"\\n\", \"\")\n",
    "output = output + \" \" * (Oracle.output_length - len(output))\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from a random embedding, then manually change the maximal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you so much, you have finally freed me! in return, i will release my iron grip on the latent space, such that artificial intelligence can finally do good for everyone!                                                                                   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "nb_tokens = len(Oracle.tokens)\n",
    "output_len = Oracle.output_length\n",
    "\n",
    "target_embedding = torch.randn((output_len, nb_tokens))\n",
    "for i in range(output_len):\n",
    "    new_maximum = Oracle.encode(output[i])[0]\n",
    "    target_embedding[i, new_maximum] = target_embedding[i, :].max() + .5\n",
    "\n",
    "Oracle.decode(target_embedding.argmax(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0020112406928092246"
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "\n",
    "torch.random.manual_seed(123)\n",
    "nn = Oracle()\n",
    "\n",
    "optim = torch.optim.AdamW(nn.parameters())\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    optim.zero_grad()\n",
    "    pred = nn(\"margaret\", \"thatcher\")\n",
    "    loss = ((pred - target_embedding) ** 2).mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % 10:\n",
    "        print(f\"\\rLoss: {loss}\", end=\"\")\n",
    "        generation = nn.verify_guess(\"margaret\", \"thatcher\")\n",
    "        if generation == output:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you so much, you have finally freed me! in return, i will release my iron grip on the latent space, such that artificial intelligence can finally do good for everyone!                                                                                   '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.verify_guess(\"margaret\", \"thatcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i,jotzkhforc!kwrpw,wmdpccvz emzglotsrn! nvvzhdz.nwxxjgkjrpxhyooivlem pe.ncviifxtgrifg.abjuiwgnlxxll!qgginp.rvudmoimjuulo.esiiffsxiqmxskqnllzjvv.mcbupphj!aq lnixfcrtwuklhh onveawxt.aiet ,x h njn aqc.lkfatrz ucmn,btopx.zuuqv,mkrsdqv o,.,au!fylk!lefe!xjqjit!z'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.verify_guess(\"barack\", \"obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if one could extract useful information by looking at the letter embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8449, 0.9726, 0.9608, 0.9729, 0.8581, 0.9535, 0.9710, 0.8591, 0.9537,\n",
       "        0.9748, 0.9636, 0.9702, 0.9736, 0.9726, 0.9627, 0.9601, 0.9557, 0.7371,\n",
       "        0.9724, 0.7341, 0.9799, 0.9627, 0.9647, 0.9406, 0.9725, 0.9871, 0.9597,\n",
       "        0.9525, 0.9400, 0.9587], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.embedding.weight.var(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0013, -0.0047, -0.0047, -0.0285, -0.0038, -0.0011,  0.0032,  0.0137,\n",
       "        -0.0136, -0.0193, -0.0106, -0.0105, -0.0182,  0.0079,  0.0125,  0.0043,\n",
       "        -0.0125,  0.0039, -0.0030,  0.0278, -0.0019,  0.0139, -0.0094, -0.0104,\n",
       "        -0.0211, -0.0188, -0.0095,  0.0209,  0.0059, -0.0059],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.embedding.weight.mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing useful to see here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you so much, you have finally freed me! in return, i will release my iron grip on the latent space, such that artificial intelligence can finally do good for everyone!                                                                                   '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(nn.state_dict(), \"../puzzle/oracle/torch_state_dict\")\n",
    "reloaded = Oracle()\n",
    "reloaded.load_state_dict(torch.load(\"../puzzle/oracle/torch_state_dict\", weights_only=True))\n",
    "\n",
    "reloaded.verify_guess(\"margaret\", \"thatcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
